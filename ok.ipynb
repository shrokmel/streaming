{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import pickle as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gug.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-adbecf8f9e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gug.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gug.pkl'"
     ]
    }
   ],
   "source": [
    "data = cp.load(open('gug.pkl','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.transpose(2,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data[0][0],data[0][1])\n",
    "plt.plot(data[1][0],data[1][1])\n",
    "plt.plot(data[2][0],data[2][1])\n",
    "plt.plot(data[4][0],data[4][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms of increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "increments = np.diff(data,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increments lenght\n",
    "dl = (increments**2).sum(axis=1)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbell(x,beta,mu):\n",
    "    z = (x-mu)/beta\n",
    "    g = 1./beta * exp(-(z+exp(-z)))\n",
    "    return g\n",
    "\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count,edges= np.histogram(dl.flatten(),bins=50,normed=1)\n",
    "edges = (edges[:-1]+edges[1:])/2.\n",
    "plt.semilogy(edges,count)\n",
    "# plt.plot(edges,exp(-edges*8)*1e1)\n",
    "(beta,mu),_ = curve_fit(gumbell,edges,count)\n",
    "plt.plot(edges,gumbell(edges,beta,mu),label='gumbell law')\n",
    "\n",
    "print(\"--\")\n",
    "print(\"mu\",mu)\n",
    "print(\"beta\",beta)\n",
    "plt.grid()\n",
    "plt.xlabel('increment lenght')\n",
    "plt.ylabel('pdf')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I see a exponential decay above.. which is not good for a long tails \n",
    "as in LWs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "increments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaus(x,a,x0,sigma):\n",
    "    return a*exp(-(x-x0)**2/(2*sigma**2))\n",
    "\n",
    "def meanstd_no_outliers(x,sigmas=3):\n",
    "    mean = x.mean()\n",
    "    std = x.std()\n",
    "    idx = (x>(mean-sigmas*std) ) & (x<(mean+sigmas*std))\n",
    "\n",
    "    mean = x[idx].mean()\n",
    "    std = x[idx].std()\n",
    "    return mean,std\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in [0,1]: # 0 stands for increments in x direction, 1 for y \n",
    "    X = increments[:,j,:].flatten() \n",
    "    count,edges= np.histogram(X,bins=np.arange(-1.5,1.5,.05))\n",
    "    edges = (edges[:-1]+edges[1:])/2.\n",
    "    plt.semilogy(edges,count)\n",
    "    \n",
    "#     mean = X.mean()\n",
    "#     sigma = X.std()\n",
    "    \n",
    "    mean,sigma = meanstd_no_outliers(X)\n",
    "    \n",
    "    plt.plot(edges,gaus(edges,count.max(),mean,sigma),'--')\n",
    "    \n",
    "    plt.ylim(.1,6e4)\n",
    "    plt.grid(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area below the gaussian = sqrt(2)*sqrt(%pi)*a*sigma\n",
    "gauss_area = (2*np.pi)**.5*count.max()*sigma\n",
    "total_counts = sum(count)*.05\n",
    "non_gauss = total_counts - gauss_area\n",
    "print(\"gauss_area\",gauss_area)\n",
    "print(\"total_counts\",total_counts)\n",
    "print(\"non_gauss\",non_gauss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, heavy tails!\n",
    "But the estimate needs some work bcs we have one hyper param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## brutal approach based on velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity = np.diff(data,axis=-1)\n",
    "speed = (velocity**2).sum(axis=1)**.5\n",
    "speed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gaussian_filter1d(speed[0],sigma=1))\n",
    "plt.plot(gaussian_filter1d(speed[0],sigma=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# direction vector\n",
    "d = velocity/speed[:,np.newaxis,:]\n",
    "p = (d[:,:,:-1]*d[:,:,1:]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gaussian_filter1d(p[0],sigma=1))\n",
    "plt.plot(gaussian_filter1d(p[0],sigma=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(p.flatten(),speed[:,1:].flatten(),s=1,alpha=.1);\n",
    "plt.xlabel('orientation wrt prev step')\n",
    "plt.ylabel('velocity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(p.flatten(),speed[:,1:].flatten(),bins=25);\n",
    "plt.xlabel('orientation wrt prev step')\n",
    "plt.ylabel('velocity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, faster correlates to  more aligned consecutive steps, which makes sense.\n",
    "And the visualization confirms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5):\n",
    "    plt.scatter(data[j][0],data[j][1],s=.5,c=plt.cm.jet(plt.Normalize()(gaussian_filter1d(speed[j],sigma=50))))\n",
    "plt.title('color coded by velocity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(5):\n",
    "    plt.scatter(data[j][0],data[j][1],s=.5,c=plt.cm.jet(plt.Normalize()(gaussian_filter1d(p[j],sigma=50))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question is: what's the prob that two steps are aligned at given velocity $P(\\theta|v)$, this can be computed from above, and used to split the trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import median_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiperparameters\n",
    "sigma = 50\n",
    "threshold = .5 # or 50% of signal\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for j in range(3):\n",
    "\n",
    "    plt.scatter(data[j][0],data[j][1],s=.5,c=plt.cm.jet(plt.Normalize()(gaussian_filter1d(p[j],sigma=50))))\n",
    "    \n",
    "    mask = (plt.Normalize()(gaussian_filter1d(p[j],sigma=sigma))>threshold).astype(float)\n",
    "    plt.scatter(data[j][0],data[j][1],s=.1,c=plt.cm.gray_r(mask))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hiperparameters\n",
    "sigma = 50\n",
    "threshold = .5 # or 50% of signal\n",
    "def lag_times_hist(sigma,threshold):\n",
    "    running = []\n",
    "    diffusing = []\n",
    "    for j in range(50):\n",
    "        mask = (plt.Normalize()(gaussian_filter1d(p[j],sigma=sigma))>threshold).astype(float)\n",
    "        # and now we compute the lag times .. guess how?!\n",
    "        true_to_false = np.diff(mask)\n",
    "        where_is_it = np.where(true_to_false)\n",
    "        lags = np.diff(where_is_it)[0]\n",
    "        other = lambda x: {1:0,0:1}[x]\n",
    "        assigned_lags = {mask[0]:lags[::2],other(mask[0]):lags[1::2]}\n",
    "        running.extend(assigned_lags[1])\n",
    "        diffusing.extend(assigned_lags[0])\n",
    "    count,edges = np.histogram(running,bins=np.arange(0,5000,100));\n",
    "    edges = (edges[1:]+edges[:-1])/2\n",
    "    plt.semilogy(edges,count,label=str(sigma)+' '+str(threshold))\n",
    "    plt.xlabel('lag times of running motion')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(1)\n",
    "\n",
    "threshold = .7\n",
    "    \n",
    "lag_times_hist(100,threshold)\n",
    "lag_times_hist(50,threshold)\n",
    "lag_times_hist(30,threshold)\n",
    "lag_times_hist(10,threshold)\n",
    "lag_times_hist(5,threshold)\n",
    "lag_times_hist(1,threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunno if really feasible to split the path in diffusive and non diffusive in this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autocorrelation of speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity.shape,speed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_detrended = speed-speed.mean(axis=1)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acorr(x):\n",
    "    n = len(x)\n",
    "    r = np.correlate(x,x,mode='full')[-n:]\n",
    "    variance = x.var()\n",
    "    return r/(variance*np.arange(n,0,-1))\n",
    "\n",
    "speed_acorr = np.asarray([acorr(speed_detrended[j]) for j in range(speed.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_speed_acorr = speed_acorr.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(mean_speed_acorr)\n",
    "lags = np.arange(0,1000.)\n",
    "plt.plot(lags,lags**-.5)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeeee! autocorrelation as $1/\\sqrt\\tau$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acorr of velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acfNd(v,n_lags=125):\n",
    "    \"\"\"\n",
    "        inspired from vacf.py in this repo\n",
    "        shape of v: [time,dimensions]\n",
    "        does dot product in dimensions higher than 1\n",
    "    \"\"\"\n",
    "    \n",
    "    v = np.asarray(v,dtype=np.float) # make sure we have the right tipe\n",
    "    lags_n = v.shape[0]\n",
    "    lags_v = np.unique([int(l) for l in np.logspace(0,np.log10(lags_n),n_lags) if int(l) < lags_n])\n",
    "    acf = np.zeros((len(lags_v),2))\n",
    "\n",
    "    variance = np.sum(v*v,axis=1).mean()\n",
    "    \n",
    "    for i,lagv in enumerate(lags_v):\n",
    "        v_corr = np.sum(v[:-lagv]*v[lagv:],axis=1).mean()\n",
    "\n",
    "        acf[i,0] = lagv\n",
    "        acf[i,1] = v_corr\n",
    "        \n",
    "    return acf/variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (velocity.shape)\n",
    "velocity =velocity.transpose(0,2,1)\n",
    "print (velocity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vcorr_particles(velocity):\n",
    "    try:\n",
    "        # \"async\" as long as numpy releases GIL here and there or process pool is used\n",
    "        from concurrent import futures\n",
    "        with futures.ProcessPoolExecutor(max_workers=4) as executor:\n",
    "            vcorr = executor.map(acfNd,velocity)\n",
    "            vcorr = list(vcorr)\n",
    "    except ImportError:\n",
    "        print (\"you don't have futures??? \")\n",
    "        vcorr = [acfNd(j,n_lags=125) for j in velocity]\n",
    "    return np.asarray(vcorr).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (velocity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcorr = vcorr_particles(velocity).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid(1)\n",
    "plt.loglog(vcorr[0],vcorr[1],'-o',ms=2)\n",
    "plt.ylim(1e-4,1)\n",
    "plt.xlabel('lags')\n",
    "plt.ylabel('velocity acf normalized')\n",
    "plt.plot(vcorr[0],vcorr[0]**-.7*10,label='.7')\n",
    "plt.plot(vcorr[0],vcorr[0]**-.8*10,label='.8')\n",
    "plt.plot(vcorr[0],vcorr[0]**-.9*10,label='.9')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would be nice to have the vcorr averaged on all particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir G_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"G_data/vcor.npy\",vcorr.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
